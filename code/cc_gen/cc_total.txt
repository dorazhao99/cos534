{'batchsize': 32, 'labels_train': '../data/cc/cc_gender_train.pkl', 'labels_val': '../data/cc/cc_gender_val.pkl', 'labels_test': None, 'num_epochs': 10, 'lr': 0.0003, 'print_freq': 50, 'num_classes': 2, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/cc'} 

Training on cpu
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/10
----------
Iter 0/72 (Epoch 0), Train Loss = 0.710
Iter 50/72 (Epoch 0), Train Loss = 0.176
train Loss: 0.3085 Acc: 0.8706  Time: 1077.5047
val Loss: 0.2421 Acc: 0.9236  Time: 1140.9376

Epoch 2/10
----------
Iter 0/72 (Epoch 1), Train Loss = 0.219
Iter 50/72 (Epoch 1), Train Loss = 0.056
train Loss: 0.1317 Acc: 0.9522  Time: 2217.8088
val Loss: 0.2337 Acc: 0.9236  Time: 2281.2275

Epoch 3/10
----------
Iter 0/72 (Epoch 2), Train Loss = 0.072
Iter 50/72 (Epoch 2), Train Loss = 0.154
train Loss: 0.1108 Acc: 0.9640  Time: 3388.4126
val Loss: 0.6818 Acc: 0.8490  Time: 3456.0284

Epoch 4/10
----------
Iter 0/72 (Epoch 3), Train Loss = 0.059
Iter 50/72 (Epoch 3), Train Loss = 0.032
train Loss: 0.1058 Acc: 0.9645  Time: 4587.3910
val Loss: 0.1405 Acc: 0.9538  Time: 4656.4725

Epoch 5/10
----------
Iter 0/72 (Epoch 4), Train Loss = 0.014
Iter 50/72 (Epoch 4), Train Loss = 0.059
train Loss: 0.0526 Acc: 0.9842  Time: 5800.9645
val Loss: 0.2769 Acc: 0.9112  Time: 5871.1208

Epoch 6/10
----------
Iter 0/72 (Epoch 5), Train Loss = 0.091
Iter 50/72 (Epoch 5), Train Loss = 0.012
train Loss: 0.0500 Acc: 0.9851  Time: 7031.0126
val Loss: 0.3018 Acc: 0.9414  Time: 7099.6371

Epoch 7/10
----------
Iter 0/72 (Epoch 6), Train Loss = 0.210
Iter 50/72 (Epoch 6), Train Loss = 0.008
train Loss: 0.0676 Acc: 0.9741  Time: 8226.8492
val Loss: 0.1458 Acc: 0.9680  Time: 8293.1043

Epoch 8/10
----------
Iter 0/72 (Epoch 7), Train Loss = 0.007
Iter 50/72 (Epoch 7), Train Loss = 0.023
train Loss: 0.0454 Acc: 0.9842  Time: 9401.4797
val Loss: 0.2000 Acc: 0.9556  Time: 9467.5165

Epoch 9/10
----------
Iter 0/72 (Epoch 8), Train Loss = 0.069
Iter 50/72 (Epoch 8), Train Loss = 0.005
train Loss: 0.0455 Acc: 0.9855  Time: 10576.3811
val Loss: 0.1939 Acc: 0.9645  Time: 10642.6681

Epoch 10/10
----------
Iter 0/72 (Epoch 9), Train Loss = 0.016
Iter 50/72 (Epoch 9), Train Loss = 0.032
train Loss: 0.0287 Acc: 0.9912  Time: 11713.7212
Epoch    10: reducing learning rate of group 0 to 3.0000e-05.
val Loss: 0.2349 Acc: 0.9627  Time: 11777.3178
Best model at 3 with lowest val loss 0.14053969183642265
Training complete in 196m 17s
Best val acc: 0.968028
