{'batchsize': 32, 'labels_train': '../data/LAOFIW/laofiw_2_label.pkl', 'labels_val': '../data/LAOFIW/laofiw_3_label.pkl', 'labels_test': None, 'num_epochs': 15, 'lr': 0.001, 'print_freq': 50, 'num_classes': 4, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/laofiw_2/'} 

Training on cuda:0
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/15
----------
Iter 0/95 (Epoch 0), Train Loss = 1.430
Iter 50/95 (Epoch 0), Train Loss = 1.088
train Loss: 1.1307 Acc: 0.5203  Time: 16.5904
val Loss: 1.0099 Acc: 0.5975  Time: 35.6051

Epoch 2/15
----------
Iter 0/95 (Epoch 1), Train Loss = 0.747
Iter 50/95 (Epoch 1), Train Loss = 0.860
train Loss: 0.8636 Acc: 0.6696  Time: 52.2171
val Loss: 1.0119 Acc: 0.5756  Time: 65.1830

Epoch 3/15
----------
Iter 0/95 (Epoch 2), Train Loss = 0.707
Iter 50/95 (Epoch 2), Train Loss = 0.784
train Loss: 0.8264 Acc: 0.6802  Time: 82.0466
val Loss: 0.9772 Acc: 0.6391  Time: 95.1785

Epoch 4/15
----------
Iter 0/95 (Epoch 3), Train Loss = 0.675
Iter 50/95 (Epoch 3), Train Loss = 0.533
train Loss: 0.6905 Acc: 0.7397  Time: 111.4458
val Loss: 0.8568 Acc: 0.6939  Time: 124.3402

Epoch 5/15
----------
Iter 0/95 (Epoch 4), Train Loss = 0.571
Iter 50/95 (Epoch 4), Train Loss = 0.733
train Loss: 0.6148 Acc: 0.7780  Time: 141.2374
val Loss: 1.1105 Acc: 0.6288  Time: 154.7625

Epoch 6/15
----------
Iter 0/95 (Epoch 5), Train Loss = 0.726
Iter 50/95 (Epoch 5), Train Loss = 0.341
train Loss: 0.5434 Acc: 0.7995  Time: 171.4977
val Loss: 0.9148 Acc: 0.6853  Time: 184.9849

Epoch 7/15
----------
Iter 0/95 (Epoch 6), Train Loss = 0.308
Iter 50/95 (Epoch 6), Train Loss = 0.559
train Loss: 0.4899 Acc: 0.8246  Time: 201.0384
val Loss: 0.7988 Acc: 0.7095  Time: 213.8532

Epoch 8/15
----------
Iter 0/95 (Epoch 7), Train Loss = 0.385
Iter 50/95 (Epoch 7), Train Loss = 0.249
train Loss: 0.3994 Acc: 0.8566  Time: 230.1638
val Loss: 1.0114 Acc: 0.6255  Time: 243.8272

Epoch 9/15
----------
Iter 0/95 (Epoch 8), Train Loss = 0.724
Iter 50/95 (Epoch 8), Train Loss = 0.187
train Loss: 0.3960 Acc: 0.8537  Time: 260.1640
val Loss: 0.8624 Acc: 0.7222  Time: 274.3964

Epoch 10/15
----------
Iter 0/95 (Epoch 9), Train Loss = 0.392
Iter 50/95 (Epoch 9), Train Loss = 0.290
train Loss: 0.3113 Acc: 0.8887  Time: 290.9192
val Loss: 1.1116 Acc: 0.6510  Time: 303.8249

Epoch 11/15
----------
Iter 0/95 (Epoch 10), Train Loss = 0.364
Iter 50/95 (Epoch 10), Train Loss = 0.459
train Loss: 0.2826 Acc: 0.8976  Time: 320.3246
val Loss: 1.2294 Acc: 0.7012  Time: 333.6315

Epoch 12/15
----------
Iter 0/95 (Epoch 11), Train Loss = 0.062
Iter 50/95 (Epoch 11), Train Loss = 0.358
train Loss: 0.2495 Acc: 0.9092  Time: 349.7039
val Loss: 1.2451 Acc: 0.6740  Time: 362.6218

Epoch 13/15
----------
Iter 0/95 (Epoch 12), Train Loss = 0.231
Iter 50/95 (Epoch 12), Train Loss = 0.364
train Loss: 0.2011 Acc: 0.9303  Time: 379.3267
Epoch    13: reducing learning rate of group 0 to 1.0000e-04.
val Loss: 1.3059 Acc: 0.6876  Time: 393.2461

Epoch 14/15
----------
Iter 0/95 (Epoch 13), Train Loss = 0.079
Iter 50/95 (Epoch 13), Train Loss = 0.083
train Loss: 0.1028 Acc: 0.9663  Time: 409.7750
val Loss: 0.8842 Acc: 0.7644  Time: 422.9332

Epoch 15/15
----------
Iter 0/95 (Epoch 14), Train Loss = 0.051
Iter 50/95 (Epoch 14), Train Loss = 0.021
train Loss: 0.0369 Acc: 0.9924  Time: 439.5810
val Loss: 0.9136 Acc: 0.7637  Time: 452.5781
Best model at 6 with lowest val loss 0.7987575584687676
Training complete in 7m 33s
Best val acc: 0.764374
