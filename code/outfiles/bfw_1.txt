{'batchsize': 32, 'labels_train': '../data/bfw/bfw_fleiss/bfw_race_1.pkl', 'labels_val': '../data/bfw/bfw_fleiss/bfw_race_2.pkl', 'labels_test': None, 'num_epochs': 10, 'lr': 0.0003, 'print_freq': 50, 'num_classes': 4, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/bfw/fleiss/bfw_race_1.json'} 

Training on cuda:0
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/10
----------
Iter 0/200 (Epoch 0), Train Loss = 1.470
Iter 50/200 (Epoch 0), Train Loss = 0.712
Iter 100/200 (Epoch 0), Train Loss = 0.409
Iter 150/200 (Epoch 0), Train Loss = 0.734
train Loss: 0.5581 Acc: 0.7887  Time: 41.7032
val Loss: 0.5392 Acc: 0.8034  Time: 74.9834

Epoch 2/10
----------
Iter 0/200 (Epoch 1), Train Loss = 0.192
Iter 50/200 (Epoch 1), Train Loss = 0.292
Iter 100/200 (Epoch 1), Train Loss = 0.274
Iter 150/200 (Epoch 1), Train Loss = 0.528
train Loss: 0.2820 Acc: 0.8955  Time: 107.6235
val Loss: 0.5018 Acc: 0.8199  Time: 134.4165

Epoch 3/10
----------
Iter 0/200 (Epoch 2), Train Loss = 0.179
Iter 50/200 (Epoch 2), Train Loss = 0.133
Iter 100/200 (Epoch 2), Train Loss = 0.098
Iter 150/200 (Epoch 2), Train Loss = 0.080
train Loss: 0.1800 Acc: 0.9358  Time: 167.0364
val Loss: 0.5953 Acc: 0.8145  Time: 192.3926

Epoch 4/10
----------
Iter 0/200 (Epoch 3), Train Loss = 0.408
Iter 50/200 (Epoch 3), Train Loss = 0.380
Iter 100/200 (Epoch 3), Train Loss = 0.028
Iter 150/200 (Epoch 3), Train Loss = 0.117
train Loss: 0.1377 Acc: 0.9521  Time: 224.6476
val Loss: 0.5989 Acc: 0.8283  Time: 250.6215

Epoch 5/10
----------
Iter 0/200 (Epoch 4), Train Loss = 0.020
Iter 50/200 (Epoch 4), Train Loss = 0.027
Iter 100/200 (Epoch 4), Train Loss = 0.009
Iter 150/200 (Epoch 4), Train Loss = 0.038
train Loss: 0.0996 Acc: 0.9649  Time: 282.8689
val Loss: 0.6917 Acc: 0.7901  Time: 308.7127

Epoch 6/10
----------
Iter 0/200 (Epoch 5), Train Loss = 0.052
Iter 50/200 (Epoch 5), Train Loss = 0.024
Iter 100/200 (Epoch 5), Train Loss = 0.302
Iter 150/200 (Epoch 5), Train Loss = 0.061
train Loss: 0.0978 Acc: 0.9654  Time: 341.3835
val Loss: 0.4808 Acc: 0.8491  Time: 367.3348

Epoch 7/10
----------
Iter 0/200 (Epoch 6), Train Loss = 0.019
Iter 50/200 (Epoch 6), Train Loss = 0.014
Iter 100/200 (Epoch 6), Train Loss = 0.115
Iter 150/200 (Epoch 6), Train Loss = 0.081
train Loss: 0.0595 Acc: 0.9815  Time: 399.9840
val Loss: 0.7016 Acc: 0.8307  Time: 425.2538

Epoch 8/10
----------
Iter 0/200 (Epoch 7), Train Loss = 0.059
Iter 50/200 (Epoch 7), Train Loss = 0.013
Iter 100/200 (Epoch 7), Train Loss = 0.073
Iter 150/200 (Epoch 7), Train Loss = 0.032
train Loss: 0.0638 Acc: 0.9746  Time: 457.3000
val Loss: 0.5462 Acc: 0.8575  Time: 483.2265

Epoch 9/10
----------
Iter 0/200 (Epoch 8), Train Loss = 0.038
Iter 50/200 (Epoch 8), Train Loss = 0.059
Iter 100/200 (Epoch 8), Train Loss = 0.038
Iter 150/200 (Epoch 8), Train Loss = 0.015
train Loss: 0.0464 Acc: 0.9826  Time: 515.5510
val Loss: 0.5799 Acc: 0.8527  Time: 541.0142

Epoch 10/10
----------
Iter 0/200 (Epoch 9), Train Loss = 0.008
Iter 50/200 (Epoch 9), Train Loss = 0.061
Iter 100/200 (Epoch 9), Train Loss = 0.108
Iter 150/200 (Epoch 9), Train Loss = 0.046
train Loss: 0.0826 Acc: 0.9718  Time: 573.2330
val Loss: 0.6653 Acc: 0.8290  Time: 599.3288
Best model at 5 with lowest val loss 0.4808385895277965
Training complete in 9m 60s
Best val acc: 0.857522
