{'batchsize': 32, 'labels_train': '../data/LAOFIW/laofiw_3_label.pkl', 'labels_val': '../data/LAOFIW/laofiw_1_label.pkl', 'labels_test': None, 'num_epochs': 15, 'lr': 0.001, 'print_freq': 50, 'num_classes': 4, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/laofiw_3/'} 

Training on cuda:0
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/15
----------
Iter 0/95 (Epoch 0), Train Loss = 1.473
Iter 50/95 (Epoch 0), Train Loss = 1.070
train Loss: 1.1860 Acc: 0.4713  Time: 16.1482
val Loss: 1.0248 Acc: 0.6009  Time: 29.1703

Epoch 2/15
----------
Iter 0/95 (Epoch 1), Train Loss = 0.789
Iter 50/95 (Epoch 1), Train Loss = 0.849
train Loss: 0.9283 Acc: 0.6311  Time: 45.8900
val Loss: 0.9158 Acc: 0.6338  Time: 58.6483

Epoch 3/15
----------
Iter 0/95 (Epoch 2), Train Loss = 0.575
Iter 50/95 (Epoch 2), Train Loss = 0.717
train Loss: 0.7964 Acc: 0.7002  Time: 74.6510
val Loss: 0.8454 Acc: 0.6663  Time: 87.2385

Epoch 4/15
----------
Iter 0/95 (Epoch 3), Train Loss = 0.755
Iter 50/95 (Epoch 3), Train Loss = 1.036
train Loss: 0.7431 Acc: 0.7168  Time: 103.7292
val Loss: 0.9294 Acc: 0.6469  Time: 116.7481

Epoch 5/15
----------
Iter 0/95 (Epoch 4), Train Loss = 0.711
Iter 50/95 (Epoch 4), Train Loss = 0.374
train Loss: 0.6509 Acc: 0.7547  Time: 133.0052
val Loss: 0.9608 Acc: 0.6573  Time: 146.0909

Epoch 6/15
----------
Iter 0/95 (Epoch 5), Train Loss = 0.404
Iter 50/95 (Epoch 5), Train Loss = 0.603
train Loss: 0.5886 Acc: 0.7843  Time: 162.6016
val Loss: 1.0240 Acc: 0.6476  Time: 175.6859

Epoch 7/15
----------
Iter 0/95 (Epoch 6), Train Loss = 0.421
Iter 50/95 (Epoch 6), Train Loss = 0.755
train Loss: 0.5010 Acc: 0.8092  Time: 191.9198
val Loss: 0.9244 Acc: 0.6918  Time: 205.8284

Epoch 8/15
----------
Iter 0/95 (Epoch 7), Train Loss = 0.286
Iter 50/95 (Epoch 7), Train Loss = 0.616
train Loss: 0.4577 Acc: 0.8315  Time: 222.5560
val Loss: 1.1372 Acc: 0.6509  Time: 235.2146

Epoch 9/15
----------
Iter 0/95 (Epoch 8), Train Loss = 0.387
Iter 50/95 (Epoch 8), Train Loss = 0.407
train Loss: 0.3892 Acc: 0.8631  Time: 251.2468
Epoch     9: reducing learning rate of group 0 to 1.0000e-04.
val Loss: 1.1723 Acc: 0.6610  Time: 264.3367

Epoch 10/15
----------
Iter 0/95 (Epoch 9), Train Loss = 0.261
Iter 50/95 (Epoch 9), Train Loss = 0.122
train Loss: 0.1790 Acc: 0.9415  Time: 280.5887
val Loss: 0.7805 Acc: 0.7639  Time: 293.6046

Epoch 11/15
----------
Iter 0/95 (Epoch 10), Train Loss = 0.135
Iter 50/95 (Epoch 10), Train Loss = 0.128
train Loss: 0.0837 Acc: 0.9814  Time: 310.3025
val Loss: 0.8275 Acc: 0.7552  Time: 322.9265

Epoch 12/15
----------
Iter 0/95 (Epoch 11), Train Loss = 0.148
Iter 50/95 (Epoch 11), Train Loss = 0.024
train Loss: 0.0595 Acc: 0.9831  Time: 339.4309
val Loss: 0.9172 Acc: 0.7596  Time: 352.0338

Epoch 13/15
----------
Iter 0/95 (Epoch 12), Train Loss = 0.009
Iter 50/95 (Epoch 12), Train Loss = 0.042
train Loss: 0.0414 Acc: 0.9900  Time: 368.1017
val Loss: 1.1165 Acc: 0.7478  Time: 381.1401

Epoch 14/15
----------
Iter 0/95 (Epoch 13), Train Loss = 0.021
Iter 50/95 (Epoch 13), Train Loss = 0.007
train Loss: 0.0252 Acc: 0.9927  Time: 398.1718
val Loss: 1.1948 Acc: 0.7552  Time: 411.0337

Epoch 15/15
----------
Iter 0/95 (Epoch 14), Train Loss = 0.019
Iter 50/95 (Epoch 14), Train Loss = 0.019
train Loss: 0.0210 Acc: 0.9960  Time: 428.4200
val Loss: 1.3296 Acc: 0.7498  Time: 441.4882
Best model at 9 with lowest val loss 0.7804785552518948
Training complete in 7m 22s
Best val acc: 0.763917
