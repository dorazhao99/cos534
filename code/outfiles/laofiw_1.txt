{'batchsize': 32, 'labels_train': '../data/LAOFIW/laofiw_1_label.pkl', 'labels_val': '../data/LAOFIW/laofiw_2_label.pkl', 'labels_test': None, 'num_epochs': 15, 'lr': 0.001, 'print_freq': 50, 'num_classes': 4, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/laofiw_1/'} 

Training on cuda:0
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/15
----------
Iter 0/94 (Epoch 0), Train Loss = 1.443
Iter 50/94 (Epoch 0), Train Loss = 0.999
train Loss: 1.1468 Acc: 0.5131  Time: 19.3901
val Loss: 1.2350 Acc: 0.5309  Time: 36.9420

Epoch 2/15
----------
Iter 0/94 (Epoch 1), Train Loss = 0.966
Iter 50/94 (Epoch 1), Train Loss = 0.836
train Loss: 0.8878 Acc: 0.6462  Time: 53.2187
val Loss: 1.1735 Acc: 0.5216  Time: 66.0694

Epoch 3/15
----------
Iter 0/94 (Epoch 2), Train Loss = 0.712
Iter 50/94 (Epoch 2), Train Loss = 0.965
train Loss: 0.7824 Acc: 0.6982  Time: 82.4919
val Loss: 0.8551 Acc: 0.6601  Time: 95.6320

Epoch 4/15
----------
Iter 0/94 (Epoch 3), Train Loss = 0.600
Iter 50/94 (Epoch 3), Train Loss = 0.782
train Loss: 0.6759 Acc: 0.7518  Time: 112.1286
val Loss: 1.1519 Acc: 0.6379  Time: 125.1984

Epoch 5/15
----------
Iter 0/94 (Epoch 4), Train Loss = 0.482
Iter 50/94 (Epoch 4), Train Loss = 0.854
train Loss: 0.6386 Acc: 0.7639  Time: 141.0156
val Loss: 0.9684 Acc: 0.6620  Time: 154.2914

Epoch 6/15
----------
Iter 0/94 (Epoch 5), Train Loss = 0.472
Iter 50/94 (Epoch 5), Train Loss = 0.776
train Loss: 0.5528 Acc: 0.8068  Time: 171.2284
val Loss: 1.3150 Acc: 0.5755  Time: 184.2844

Epoch 7/15
----------
Iter 0/94 (Epoch 6), Train Loss = 0.382
Iter 50/94 (Epoch 6), Train Loss = 0.484
train Loss: 0.4849 Acc: 0.8313  Time: 201.3287
val Loss: 1.2444 Acc: 0.6224  Time: 214.6759

Epoch 8/15
----------
Iter 0/94 (Epoch 7), Train Loss = 0.415
Iter 50/94 (Epoch 7), Train Loss = 0.565
train Loss: 0.5702 Acc: 0.7877  Time: 230.9103
val Loss: 0.9525 Acc: 0.6786  Time: 243.9046

Epoch 9/15
----------
Iter 0/94 (Epoch 8), Train Loss = 0.137
Iter 50/94 (Epoch 8), Train Loss = 0.416
train Loss: 0.3976 Acc: 0.8625  Time: 260.2567
Epoch     9: reducing learning rate of group 0 to 1.0000e-04.
val Loss: 0.9235 Acc: 0.7014  Time: 273.4694

Epoch 10/15
----------
Iter 0/94 (Epoch 9), Train Loss = 0.488
Iter 50/94 (Epoch 9), Train Loss = 0.136
train Loss: 0.1987 Acc: 0.9370  Time: 290.0066
val Loss: 0.7901 Acc: 0.7466  Time: 302.9996

Epoch 11/15
----------
Iter 0/94 (Epoch 10), Train Loss = 0.109
Iter 50/94 (Epoch 10), Train Loss = 0.040
train Loss: 0.1030 Acc: 0.9738  Time: 319.5880
val Loss: 0.8491 Acc: 0.7489  Time: 332.3694

Epoch 12/15
----------
Iter 0/94 (Epoch 11), Train Loss = 0.039
Iter 50/94 (Epoch 11), Train Loss = 0.086
train Loss: 0.0654 Acc: 0.9826  Time: 348.9393
val Loss: 0.9192 Acc: 0.7522  Time: 362.5407

Epoch 13/15
----------
Iter 0/94 (Epoch 12), Train Loss = 0.076
Iter 50/94 (Epoch 12), Train Loss = 0.046
train Loss: 0.0482 Acc: 0.9863  Time: 379.0621
val Loss: 1.0720 Acc: 0.7469  Time: 392.3020

Epoch 14/15
----------
Iter 0/94 (Epoch 13), Train Loss = 0.031
Iter 50/94 (Epoch 13), Train Loss = 0.012
train Loss: 0.0310 Acc: 0.9903  Time: 408.3254
val Loss: 1.4227 Acc: 0.7410  Time: 421.2654

Epoch 15/15
----------
Iter 0/94 (Epoch 14), Train Loss = 0.001
Iter 50/94 (Epoch 14), Train Loss = 0.019
train Loss: 0.0208 Acc: 0.9940  Time: 439.2363
val Loss: 1.4511 Acc: 0.7364  Time: 452.3271
Best model at 9 with lowest val loss 0.790093639925206
Training complete in 7m 33s
Best val acc: 0.752230
