{'batchsize': 32, 'labels_train': '../data/bfw/bfw_fleiss/bfw_race_2.pkl', 'labels_val': '../data/bfw/bfw_fleiss/bfw_race_1.pkl', 'labels_test': None, 'num_epochs': 10, 'lr': 0.0003, 'print_freq': 50, 'num_classes': 4, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/bfw/fleiss/bfw_race_2.json'} 

Training on cuda:0
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/10
----------
Iter 0/201 (Epoch 0), Train Loss = 1.365
Iter 50/201 (Epoch 0), Train Loss = 0.549
Iter 100/201 (Epoch 0), Train Loss = 0.421
Iter 150/201 (Epoch 0), Train Loss = 0.591
Iter 200/201 (Epoch 0), Train Loss = 0.107
train Loss: 0.5537 Acc: 0.7909  Time: 31.3421
val Loss: 0.5726 Acc: 0.7878  Time: 57.3959

Epoch 2/10
----------
Iter 0/201 (Epoch 1), Train Loss = 0.280
Iter 50/201 (Epoch 1), Train Loss = 0.278
Iter 100/201 (Epoch 1), Train Loss = 0.688
Iter 150/201 (Epoch 1), Train Loss = 0.371
Iter 200/201 (Epoch 1), Train Loss = 0.212
train Loss: 0.2890 Acc: 0.8959  Time: 89.8755
val Loss: 0.6451 Acc: 0.7920  Time: 115.1362

Epoch 3/10
----------
Iter 0/201 (Epoch 2), Train Loss = 0.126
Iter 50/201 (Epoch 2), Train Loss = 0.246
Iter 100/201 (Epoch 2), Train Loss = 0.183
Iter 150/201 (Epoch 2), Train Loss = 0.092
Iter 200/201 (Epoch 2), Train Loss = 0.035
train Loss: 0.1826 Acc: 0.9365  Time: 147.8114
val Loss: 0.4578 Acc: 0.8471  Time: 174.3515

Epoch 4/10
----------
Iter 0/201 (Epoch 3), Train Loss = 0.072
Iter 50/201 (Epoch 3), Train Loss = 0.106
Iter 100/201 (Epoch 3), Train Loss = 0.070
Iter 150/201 (Epoch 3), Train Loss = 0.014
Iter 200/201 (Epoch 3), Train Loss = 0.079
train Loss: 0.1321 Acc: 0.9522  Time: 206.7796
val Loss: 0.5259 Acc: 0.8451  Time: 231.6888

Epoch 5/10
----------
Iter 0/201 (Epoch 4), Train Loss = 0.047
Iter 50/201 (Epoch 4), Train Loss = 0.113
Iter 100/201 (Epoch 4), Train Loss = 0.089
Iter 150/201 (Epoch 4), Train Loss = 0.078
Iter 200/201 (Epoch 4), Train Loss = 0.005
train Loss: 0.1099 Acc: 0.9579  Time: 264.0269
slurmstepd: error: *** JOB 1091549 ON adroit-h11g1 CANCELLED AT 2021-05-02T01:07:45 ***
