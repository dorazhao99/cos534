{'batchsize': 32, 'labels_train': '../data/bfw/bfw_fleiss/bfw_gender_3.pkl', 'labels_val': '../data/bfw/bfw_fleiss/bfw_gender_1.pkl', 'labels_test': None, 'num_epochs': 10, 'lr': 0.0003, 'print_freq': 50, 'num_classes': 2, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/bfw/fleiss/bfw_gender_3'} 

Training on cuda:0
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/10
----------
Iter 0/201 (Epoch 0), Train Loss = 0.703
Iter 50/201 (Epoch 0), Train Loss = 0.380
Iter 100/201 (Epoch 0), Train Loss = 0.170
Iter 150/201 (Epoch 0), Train Loss = 0.108
Iter 200/201 (Epoch 0), Train Loss = 0.016
train Loss: 0.2461 Acc: 0.8956  Time: 35.6187
val Loss: 0.4053 Acc: 0.8698  Time: 62.8355

Epoch 2/10
----------
Iter 0/201 (Epoch 1), Train Loss = 0.037
Iter 50/201 (Epoch 1), Train Loss = 0.111
Iter 100/201 (Epoch 1), Train Loss = 0.318
Iter 150/201 (Epoch 1), Train Loss = 0.255
Iter 200/201 (Epoch 1), Train Loss = 0.010
train Loss: 0.1386 Acc: 0.9460  Time: 96.5423
val Loss: 0.2613 Acc: 0.9071  Time: 123.3209

Epoch 3/10
----------
Iter 0/201 (Epoch 2), Train Loss = 0.080
Iter 50/201 (Epoch 2), Train Loss = 0.124
Iter 100/201 (Epoch 2), Train Loss = 0.147
Iter 150/201 (Epoch 2), Train Loss = 0.081
Iter 200/201 (Epoch 2), Train Loss = 0.065
train Loss: 0.1029 Acc: 0.9599  Time: 157.3685
val Loss: 0.2368 Acc: 0.9131  Time: 185.4116

Epoch 4/10
----------
Iter 0/201 (Epoch 3), Train Loss = 0.055
Iter 50/201 (Epoch 3), Train Loss = 0.080
Iter 100/201 (Epoch 3), Train Loss = 0.081
Iter 150/201 (Epoch 3), Train Loss = 0.023
Iter 200/201 (Epoch 3), Train Loss = 0.014
train Loss: 0.0775 Acc: 0.9713  Time: 219.3768
val Loss: 0.4297 Acc: 0.8686  Time: 247.1511

Epoch 5/10
----------
Iter 0/201 (Epoch 4), Train Loss = 0.043
Iter 50/201 (Epoch 4), Train Loss = 0.019
Iter 100/201 (Epoch 4), Train Loss = 0.021
Iter 150/201 (Epoch 4), Train Loss = 0.113
Iter 200/201 (Epoch 4), Train Loss = 0.039
train Loss: 0.0641 Acc: 0.9753  Time: 281.0213
val Loss: 0.3288 Acc: 0.9096  Time: 308.0183

Epoch 6/10
----------
Iter 0/201 (Epoch 5), Train Loss = 0.089
Iter 50/201 (Epoch 5), Train Loss = 0.004
Iter 100/201 (Epoch 5), Train Loss = 0.039
Iter 150/201 (Epoch 5), Train Loss = 0.018
Iter 200/201 (Epoch 5), Train Loss = 0.005
train Loss: 0.0607 Acc: 0.9761  Time: 341.8597
val Loss: 0.2325 Acc: 0.9215  Time: 368.8807

Epoch 7/10
----------
Iter 0/201 (Epoch 6), Train Loss = 0.016
Iter 50/201 (Epoch 6), Train Loss = 0.061
Iter 100/201 (Epoch 6), Train Loss = 0.079
Iter 150/201 (Epoch 6), Train Loss = 0.014
Iter 200/201 (Epoch 6), Train Loss = 0.460
train Loss: 0.0388 Acc: 0.9849  Time: 402.9448
val Loss: 0.3697 Acc: 0.9066  Time: 430.7388

Epoch 8/10
----------
Iter 0/201 (Epoch 7), Train Loss = 0.009
Iter 50/201 (Epoch 7), Train Loss = 0.040
Iter 100/201 (Epoch 7), Train Loss = 0.014
Iter 150/201 (Epoch 7), Train Loss = 0.005
Iter 200/201 (Epoch 7), Train Loss = 0.555
train Loss: 0.0653 Acc: 0.9764  Time: 464.6847
val Loss: 0.2789 Acc: 0.9179  Time: 491.5903

Epoch 9/10
----------
Iter 0/201 (Epoch 8), Train Loss = 0.010
Iter 50/201 (Epoch 8), Train Loss = 0.186
Iter 100/201 (Epoch 8), Train Loss = 0.024
Iter 150/201 (Epoch 8), Train Loss = 0.094
Iter 200/201 (Epoch 8), Train Loss = 0.000
train Loss: 0.0464 Acc: 0.9830  Time: 525.2540
val Loss: 0.2576 Acc: 0.9268  Time: 552.8696

Epoch 10/10
----------
Iter 0/201 (Epoch 9), Train Loss = 0.001
Iter 50/201 (Epoch 9), Train Loss = 0.008
Iter 100/201 (Epoch 9), Train Loss = 0.004
Iter 150/201 (Epoch 9), Train Loss = 0.114
Iter 200/201 (Epoch 9), Train Loss = 0.004
train Loss: 0.0308 Acc: 0.9899  Time: 586.9272
val Loss: 0.3127 Acc: 0.9214  Time: 613.8975
Best model at 5 with lowest val loss 0.232539030464184
Training complete in 10m 15s
Best val acc: 0.926848
