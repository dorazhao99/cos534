Training classifier
{'batchsize': 64, 'labels_train': '/n/fs/visualai-scr/sharonz/fairface/labels_race_train_80.pkl', 'labels_val': '/n/fs/visualai-scr/sharonz/fairface/labels_race_train_20.pkl', 'labels_test': None, 'num_epochs': 15, 'lr': 0.0001, 'print_freq': 500, 'num_classes': 4, 'model_path': None, 'dtype': torch.float32, 'outdir': '../results/fairface/race'} 

Training on cuda:0
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.0.conv3.weight
	 layer1.0.bn3.weight
	 layer1.0.bn3.bias
	 layer1.0.downsample.0.weight
	 layer1.0.downsample.1.weight
	 layer1.0.downsample.1.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer1.1.conv3.weight
	 layer1.1.bn3.weight
	 layer1.1.bn3.bias
	 layer1.2.conv1.weight
	 layer1.2.bn1.weight
	 layer1.2.bn1.bias
	 layer1.2.conv2.weight
	 layer1.2.bn2.weight
	 layer1.2.bn2.bias
	 layer1.2.conv3.weight
	 layer1.2.bn3.weight
	 layer1.2.bn3.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.conv3.weight
	 layer2.0.bn3.weight
	 layer2.0.bn3.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer2.1.conv3.weight
	 layer2.1.bn3.weight
	 layer2.1.bn3.bias
	 layer2.2.conv1.weight
	 layer2.2.bn1.weight
	 layer2.2.bn1.bias
	 layer2.2.conv2.weight
	 layer2.2.bn2.weight
	 layer2.2.bn2.bias
	 layer2.2.conv3.weight
	 layer2.2.bn3.weight
	 layer2.2.bn3.bias
	 layer2.3.conv1.weight
	 layer2.3.bn1.weight
	 layer2.3.bn1.bias
	 layer2.3.conv2.weight
	 layer2.3.bn2.weight
	 layer2.3.bn2.bias
	 layer2.3.conv3.weight
	 layer2.3.bn3.weight
	 layer2.3.bn3.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.conv3.weight
	 layer3.0.bn3.weight
	 layer3.0.bn3.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer3.1.conv3.weight
	 layer3.1.bn3.weight
	 layer3.1.bn3.bias
	 layer3.2.conv1.weight
	 layer3.2.bn1.weight
	 layer3.2.bn1.bias
	 layer3.2.conv2.weight
	 layer3.2.bn2.weight
	 layer3.2.bn2.bias
	 layer3.2.conv3.weight
	 layer3.2.bn3.weight
	 layer3.2.bn3.bias
	 layer3.3.conv1.weight
	 layer3.3.bn1.weight
	 layer3.3.bn1.bias
	 layer3.3.conv2.weight
	 layer3.3.bn2.weight
	 layer3.3.bn2.bias
	 layer3.3.conv3.weight
	 layer3.3.bn3.weight
	 layer3.3.bn3.bias
	 layer3.4.conv1.weight
	 layer3.4.bn1.weight
	 layer3.4.bn1.bias
	 layer3.4.conv2.weight
	 layer3.4.bn2.weight
	 layer3.4.bn2.bias
	 layer3.4.conv3.weight
	 layer3.4.bn3.weight
	 layer3.4.bn3.bias
	 layer3.5.conv1.weight
	 layer3.5.bn1.weight
	 layer3.5.bn1.bias
	 layer3.5.conv2.weight
	 layer3.5.bn2.weight
	 layer3.5.bn2.bias
	 layer3.5.conv3.weight
	 layer3.5.bn3.weight
	 layer3.5.bn3.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.conv3.weight
	 layer4.0.bn3.weight
	 layer4.0.bn3.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 layer4.1.conv3.weight
	 layer4.1.bn3.weight
	 layer4.1.bn3.bias
	 layer4.2.conv1.weight
	 layer4.2.bn1.weight
	 layer4.2.bn1.bias
	 layer4.2.conv2.weight
	 layer4.2.bn2.weight
	 layer4.2.bn2.bias
	 layer4.2.conv3.weight
	 layer4.2.bn3.weight
	 layer4.2.bn3.bias
	 fc.weight
	 fc.bias

Epoch 1/15
----------
Iter 0/802 (Epoch 0), Train Loss = 1.440
Iter 500/802 (Epoch 0), Train Loss = 0.449
train Loss: 0.5199 Acc: 0.8018  Time: 2091.1826
val Loss: 0.4069 Acc: 0.8514  Time: 2613.1714

Epoch 2/15
----------
Iter 0/802 (Epoch 1), Train Loss = 0.336
Iter 500/802 (Epoch 1), Train Loss = 0.344
train Loss: 0.3043 Acc: 0.8925  Time: 2869.9466
val Loss: 0.4054 Acc: 0.8523  Time: 2933.1173

Epoch 3/15
----------
Iter 0/802 (Epoch 2), Train Loss = 0.112
Iter 500/802 (Epoch 2), Train Loss = 0.155
train Loss: 0.1970 Acc: 0.9299  Time: 3201.9522
val Loss: 0.4338 Acc: 0.8566  Time: 3259.2231

Epoch 4/15
----------
Iter 0/802 (Epoch 3), Train Loss = 0.113
Iter 500/802 (Epoch 3), Train Loss = 0.094
train Loss: 0.1224 Acc: 0.9569  Time: 3525.9593
val Loss: 0.5208 Acc: 0.8466  Time: 3584.2672

Epoch 5/15
----------
Iter 0/802 (Epoch 4), Train Loss = 0.072
Iter 500/802 (Epoch 4), Train Loss = 0.150
train Loss: 0.0886 Acc: 0.9686  Time: 3845.5469
val Loss: 0.5129 Acc: 0.8558  Time: 3901.4939

Epoch 6/15
----------
Iter 0/802 (Epoch 5), Train Loss = 0.092
Iter 500/802 (Epoch 5), Train Loss = 0.093
train Loss: 0.0732 Acc: 0.9745  Time: 4160.9629
val Loss: 0.5219 Acc: 0.8540  Time: 4215.7243

Epoch 7/15
----------
Iter 0/802 (Epoch 6), Train Loss = 0.072
slurmstepd: error: *** JOB 6090857 ON node017 CANCELLED AT 2021-04-30T10:04:54 ***
